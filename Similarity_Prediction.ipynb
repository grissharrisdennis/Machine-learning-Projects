{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJWl4dobT3KljsP85czFS9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grissharrisdennis/Machine-learning-Projects/blob/main/Similarity_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Similarity Prediction\n",
        "\n",
        "Molecular similarity assessments using machine learning.\n",
        "Useful for the prediction of molecular similarity evaluations by humans.\n",
        "\n",
        "Molecular similarity is an impressively broad topic with many implications in several areas of chemistry. Its roots lie in the paradigm that ‘similar molecules have similar properties’. For this reason, methods for determining molecular similarity find wide application in pharmaceutical companies, e.g., in the context of structure-activity relationships. The similarity evaluation is also used in the field of chemical legislation, specifically in the procedure to judge if a new molecule can obtain the status of orphan drug with the consequent financial benefits. For this procedure, the European Medicines Agency uses experts’ judgments. It is clear that the perception of the similarity depends on the observer, so the development of models to reproduce the human perception is useful.\n",
        "\n",
        "The dataset was created by Enrico Gandini during his PhD at Università degli Studi di Milano.\n",
        "\n",
        "[Link to the dataset](https://archive.ics.uci.edu/dataset/750/similarity+prediction-1)[click here]\n",
        "\n",
        "# Acknowledgements\n",
        "Gandini, Enrico, Gilles Marcou, Fanny Bonachera, Alexandre Varnek, Stefano Pieraccini, and Maurizio Sironi. 2022.\n",
        " \"Molecular Similarity Perception Based on Machine-Learning Models\" International Journal of Molecular Sciences 23, no. 11: 6114. https://doi.org/10.3390/ijms23116114\n",
        "\n"
      ],
      "metadata": {
        "id": "K69JGML9l723"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cairosvg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv8fus9iirWC",
        "outputId": "c4aeb24f-bc55-4505-aa2b-d9743f63e0c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cairosvg\n",
            "  Downloading CairoSVG-2.7.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m626.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cairocffi (from cairosvg)\n",
            "  Downloading cairocffi-1.6.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cssselect2 (from cairosvg)\n",
            "  Downloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cairosvg) (9.4.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.2.1)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cairocffi->cairosvg) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2->cairosvg) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.21)\n",
            "Installing collected packages: cssselect2, cairocffi, cairosvg\n",
            "Successfully installed cairocffi-1.6.1 cairosvg-2.7.1 cssselect2-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "fl4baghra1va"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import cairosvg\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "cmpp1xfGy4X8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5a59e9c-b606-48d2-c403-c8e1ff0769a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_images_path='/content/drive/My Drive/dataset_Similarity_Prediction/original_training_set/images_2D'\n",
        "train_data_images=os.listdir('/content/drive/My Drive/dataset_Similarity_Prediction/original_training_set/images_2D')\n",
        "train_data_conformers=os.listdir('/content/drive/My Drive/dataset_Similarity_Prediction/original_training_set/conformers_3D')\n",
        "train_data=pd.read_csv('/content/drive/My Drive/dataset_Similarity_Prediction/original_training_set/original_training_set.csv')"
      ],
      "metadata": {
        "id": "fpipWuny66UE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gk5Ph36OhaX",
        "outputId": "0e7014b8-3c0d-48f4-de4e-31cc0efc778e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    id_pair                          curated_smiles_molecule_a  \\\n",
            "0         1                         CCN(CC)CC(=O)Nc1c(C)cccc1C   \n",
            "1         2  Cc1nc2n(c(=O)c1CCN1CCC(c3noc4cc(F)ccc34)CC1)CC...   \n",
            "2         3                                 COc1ccccc1OCC(O)CO   \n",
            "3         4   CCOc1ccccc1OCCN[C@H](C)Cc1ccc(OC)c(S(N)(=O)=O)c1   \n",
            "4         5                                 C[C@H](N)Cc1ccccc1   \n",
            "..      ...                                                ...   \n",
            "95       96  CCC(=O)O[C@]1(C(=O)CCl)[C@@H](C)C[C@H]2[C@@H]3...   \n",
            "96       97                    C[C@H](N)[C@H](O)c1ccc(O)c(O)c1   \n",
            "97       98                      CCOC(=O)C1(c2ccccc2)CCN(C)CC1   \n",
            "98       99  CC1(C)O[C@@H]2C[C@H]3[C@@H]4C[C@H](F)C5=CC(=O)...   \n",
            "99      100  CC(=O)OCC(=O)[C@@]1(OC(C)=O)[C@@H](C)C[C@H]2[C...   \n",
            "\n",
            "                            curated_smiles_molecule_b  tanimoto_cdk_Extended  \\\n",
            "0                   CCCN1CCCC[C@H]1C(=O)Nc1c(C)cccc1C               0.641434   \n",
            "1   Cc1nc2n(c(=O)c1CCN1CCC(c3noc4cc(F)ccc34)CC1)CCCC2               0.928846   \n",
            "2                    COC(=O)CCc1ccc(OCC(O)CNC(C)C)cc1               0.381119   \n",
            "3         CC(C)C(=O)Nc1ccc([N+](=O)[O-])c(C(F)(F)F)c1               0.213429   \n",
            "4                                   CC(C)(N)Cc1ccccc1               0.905660   \n",
            "..                                                ...                    ...   \n",
            "95  CC(=O)S[C@@H]1CC2=CC(=O)CC[C@]2(C)[C@H]2CC[C@@...               0.483240   \n",
            "96                        C[C@@H](N)[C@@H](O)c1ccccc1               0.637755   \n",
            "97                        N[C@@H](Cc1ccc(O)cc1)C(=O)O               0.313869   \n",
            "98  C[C@H]1C[C@H]2[C@@H]3CC[C@](O)(C(=O)CO)[C@@]3(...               0.618243   \n",
            "99  CC1(C)O[C@@H]2C[C@H]3[C@@H]4C[C@H](F)C5=CC(=O)...               0.807927   \n",
            "\n",
            "    TanimotoCombo  frac_similar  \n",
            "0           1.623        0.4688  \n",
            "1           1.812        0.9375  \n",
            "2           1.064        0.1406  \n",
            "3           0.674        0.0313  \n",
            "4           1.690        0.8828  \n",
            "..            ...           ...  \n",
            "95          1.145        0.3413  \n",
            "96          1.430        0.7480  \n",
            "97          1.057        0.0159  \n",
            "98          1.579        0.6772  \n",
            "99          1.389        0.7638  \n",
            "\n",
            "[100 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = train_data['id_pair']\n",
        "smiles_a = train_data['curated_smiles_molecule_a']\n",
        "smiles_b = train_data['curated_smiles_molecule_b']\n",
        "tanimoto_coefficients = train_data['tanimoto_cdk_Extended']\n",
        "tanimoto_combo = train_data['TanimotoCombo']\n",
        "frac_similar = train_data['frac_similar']\n"
      ],
      "metadata": {
        "id": "OqshN7GjjfOW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_images_from_svg(svg_file):\n",
        "    png_file = svg_file.replace('.svg', '.png')\n",
        "\n",
        "    # Convert SVG to PNG using CairoSVG\n",
        "    cairosvg.svg2png(url=svg_file, write_to=png_file)\n",
        "    return png_file"
      ],
      "metadata": {
        "id": "jw-GLOAfRzZX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image):\n",
        "  img = Image.open(image)\n",
        "  img = img.convert('RGB')  # Ensure it's in RGB format\n",
        "\n",
        "    # Convert image to array\n",
        "  img_array = np.array(img)\n",
        "  img_array = img_array.reshape((1,) + img_array.shape)  # Add batch dimension\n",
        "\n",
        "    # Define and apply transformations\n",
        "  datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True\n",
        "    )\n",
        "  transformed_image = datagen.random_transform(img_array)\n",
        "  standardized_image = datagen.standardize(transformed_image)\n",
        "\n",
        "  return standardized_image[0]"
      ],
      "metadata": {
        "id": "7HtUvENnJr56"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svg_files = [os.path.join(train_data_images_path, file) for file in train_data_images if file.endswith('.svg')]\n",
        "a_images=[]\n",
        "b_images=[]\n",
        "for svg_file in svg_files:\n",
        "    png_img_path = extract_images_from_svg(svg_file)\n",
        "    #png_img_path=preprocess_image(png_img_p)\n",
        "    if png_img_path[104:105]=='a':\n",
        "      a_images.append(png_img_path)\n",
        "    elif png_img_path[104:105]=='b':\n",
        "      b_images.append(png_img_path)"
      ],
      "metadata": {
        "id": "tIlU7ma6ULn0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images_data = [[] for _ in range(101)]  # Initialize a list of lists for each number (0-100)\n",
        "for img_path in a_images + b_images:\n",
        "    molecule_num = int(img_path.split('_')[-1][:3])  # Extract the molecule number\n",
        "    images_data[molecule_num].append(img_path)"
      ],
      "metadata": {
        "id": "LBghB6Ra8GCt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in images_data:\n",
        "  for j in i:\n",
        "    j=preprocess_image(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "E6E8A5VaPN7v",
        "outputId": "89e1ed9d-6fc6-4bbb-db06-a22933eb1566"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-e7b5fb205a7b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-31-2b11ae54d430>\u001b[0m in \u001b[0;36mpreprocess_image\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mhorizontal_flip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mtransformed_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mstandardized_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mrandom_transform\u001b[0;34m(self, x, seed)\u001b[0m\n\u001b[1;32m   2057\u001b[0m         \"\"\"\n\u001b[1;32m   2058\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mapply_transform\u001b[0;34m(self, x, transform_parameters)\u001b[0m\n\u001b[1;32m   2010\u001b[0m         \u001b[0mimg_channel_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel_axis\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2012\u001b[0;31m         x = apply_affine_transform(\n\u001b[0m\u001b[1;32m   2013\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m             \u001b[0mtransform_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"theta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/preprocessing/image.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[0;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[1;32m   2544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2546\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input arrays must be multi-channel 2D images.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2547\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchannel_axis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m         raise ValueError(\n",
            "\u001b[0;31mValueError\u001b[0m: Input arrays must be multi-channel 2D images."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height, img_channels = 64, 64, 3"
      ],
      "metadata": {
        "id": "MlgZvN6JO5ow"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert images_data to numpy arrays for input to the model\n",
        "image_pairs = np.array(images_data)  # Assuming images_data contains pairs of preprocessed images\n",
        "frac_similar_values = np.array(train_data['frac_similar'])  # Assuming frac_similar is a column from train_data\n",
        "\n",
        "# Assuming your image_pairs are of shape (num_samples, 2, img_width, img_height, img_channels)\n",
        "# Reshape to (num_samples, img_width, img_height, img_channels) for each image in the pair\n",
        "#image_pairs = image_pairs.reshape(-1, 2, img_width, img_height, img_channels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sqdxt2XN3w4",
        "outputId": "a00158f8-74bb-4af6-f823-18d7f1c3f749"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-04c2c5774ed5>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  image_pairs = np.array(images_data)  # Assuming images_data contains pairs of preprocessed images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height, img_channels = 64, 64, 3  # Update with your image dimensions\n",
        "\n",
        "# Define inputs for image pairs\n",
        "input_1 = Input(shape=(img_width, img_height, img_channels))\n",
        "input_2 = Input(shape=(img_width, img_height, img_channels))\n",
        "\n",
        "# CNN for image processing\n",
        "convolutional_layer = Conv2D(32, (3, 3), activation='relu')\n",
        "flatten_layer = Flatten()\n",
        "\n",
        "# Process first image\n",
        "x1 = convolutional_layer(input_1)\n",
        "x1 = flatten_layer(x1)\n",
        "\n",
        "# Process second image\n",
        "x2 = convolutional_layer(input_2)\n",
        "x2 = flatten_layer(x2)\n",
        "\n",
        "# Concatenate processed image representations\n",
        "combined = Concatenate()([x1, x2])\n",
        "\n",
        "# Merge with frac_similar input\n",
        "frac_similar_input = Input(shape=(1,))\n",
        "combined_with_frac_similar = Concatenate()([combined, frac_similar_input])\n",
        "\n",
        "# Output layer\n",
        "output = Dense(1, activation='sigmoid')(combined_with_frac_similar)  # Sigmoid for similarity prediction\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=[input_1, input_2, frac_similar_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XA0HkLfUN7pu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit([image_pairs[:, 0], image_pairs[:, 1], frac_similar_values],\n",
        "          frac_similar_values,  # Assuming similarity as the target\n",
        "          epochs=10, batch_size=32, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "xcjkcRmOOFSh",
        "outputId": "8405d29d-4d63-4a08-ff6e-b30191320f57"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-13ea4b00a6da>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit([image_pairs[:, 0], image_pairs[:, 1], frac_similar_values], \n\u001b[0m\u001b[1;32m      3\u001b[0m           \u001b[0mfrac_similar_values\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Assuming similarity as the target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           epochs=10, batch_size=32, validation_split=0.2)\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ]
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grissharrisdennis/Machine-learning-Projects/blob/main/Similarity_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K69JGML9l723"
      },
      "source": [
        "# Similarity Prediction\n",
        "\n",
        "Molecular similarity assessments using machine learning.\n",
        "Useful for the prediction of molecular similarity evaluations by humans.\n",
        "\n",
        "Molecular similarity is an impressively broad topic with many implications in several areas of chemistry. Its roots lie in the paradigm that ‘similar molecules have similar properties’. For this reason, methods for determining molecular similarity find wide application in pharmaceutical companies, e.g., in the context of structure-activity relationships. The similarity evaluation is also used in the field of chemical legislation, specifically in the procedure to judge if a new molecule can obtain the status of orphan drug with the consequent financial benefits. For this procedure, the European Medicines Agency uses experts’ judgments. It is clear that the perception of the similarity depends on the observer, so the development of models to reproduce the human perception is useful.\n",
        "\n",
        "The dataset was created by Enrico Gandini during his PhD at Università degli Studi di Milano.\n",
        "\n",
        "[Link to the dataset](https://archive.ics.uci.edu/dataset/750/similarity+prediction-1)[click here]\n",
        "\n",
        "# Acknowledgements\n",
        "Gandini, Enrico, Gilles Marcou, Fanny Bonachera, Alexandre Varnek, Stefano Pieraccini, and Maurizio Sironi. 2022.\n",
        " \"Molecular Similarity Perception Based on Machine-Learning Models\" International Journal of Molecular Sciences 23, no. 11: 6114. https://doi.org/10.3390/ijms23116114\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNpp3hFl9baa",
        "outputId": "5345e4b5-1c98-482d-b502-9cd030192a7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "by44DYSq9SSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmpp1xfGy4X8",
        "outputId": "c07f1420-b4e3-466c-f416-4923c55509ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpipWuny66UE"
      },
      "outputs": [],
      "source": [
        "#train_data_images_path='/content/drive/My Drive/dataset_Similarity_Prediction/original_training_set/images_2D'\n",
        "#train_data_images=os.listdir('/content/drive/My Drive/dataset_Similarity_Prediction/original_training_set/images_2D')\n",
        "#train_data_conformers=os.listdir('/content/drive/My Drive/dataset_Similarity_Prediction/original_training_set/conformers_3D')\n",
        "train_data=pd.read_csv('/content/drive/My Drive/dataset_Similarity_Prediction/original_training_set/original_training_set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=pd.read_csv('/content/drive/My Drive/dataset_Similarity_Prediction/new_dataset/new_dataset.csv')"
      ],
      "metadata": {
        "id": "G3rZAEvF7nQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqshN7GjjfOW"
      },
      "outputs": [],
      "source": [
        "ids = train_data['id_pair']\n",
        "smiles_a = train_data['curated_smiles_molecule_a']\n",
        "smiles_b = train_data['curated_smiles_molecule_b']\n",
        "tanimoto_coefficients = train_data['tanimoto_cdk_Extended']\n",
        "tanimoto_combo = train_data['TanimotoCombo']\n",
        "frac_similar = train_data['frac_similar']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tids = test_data['id_pair']\n",
        "tsmiles_a = test_data['curated_smiles_molecule_a']\n",
        "tsmiles_b = test_data['curated_smiles_molecule_b']\n",
        "ttanimoto_coefficients = test_data['tanimoto_cdk_Extended']\n",
        "ttanimoto_combo = test_data['TanimotoCombo']\n",
        "tfrac_similar = test_data['frac_similar']"
      ],
      "metadata": {
        "id": "ZfWaXGir71sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSXIdtGDmyUl"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "def convert_smiles_to_fingerprints(smiles):\n",
        "    # Convert SMILES to RDKit Mol object\n",
        "    molecule = Chem.MolFromSmiles(smiles)\n",
        "\n",
        "    # Generate molecular fingerprint (Morgan fingerprint in this example)\n",
        "    fingerprint = AllChem.GetMorganFingerprintAsBitVect(molecule, 2)\n",
        "\n",
        "    # Convert RDKit fingerprint object to bit vector\n",
        "    fingerprint_bitvector = list(fingerprint.ToBitString())\n",
        "\n",
        "    return fingerprint_bitvector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rz_0dxNvljKu"
      },
      "outputs": [],
      "source": [
        "smiles_list = []\n",
        "for i, j in zip(smiles_a, smiles_b):\n",
        "    fingerprint_i = convert_smiles_to_fingerprints(i)\n",
        "    fingerprint_j = convert_smiles_to_fingerprints(j)\n",
        "\n",
        "    smiles_list.append([fingerprint_i, fingerprint_j])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Flatten the list of fingerprints\n",
        "flattened_smiles_list = np.array(smiles_list).reshape(len(smiles_list), -1)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(flattened_smiles_list, frac_similar, test_size=0.2, random_state=42)\n",
        "\n",
        "# Example preprocessing for numerical and categorical data\n",
        "numerical_scaler = StandardScaler()\n",
        "X_train_numerical = numerical_scaler.fit_transform(X_train)\n",
        "X_val_numerical = numerical_scaler.transform(X_val)\n",
        "\n",
        "# Combine y_train and y_val for label encoding\n",
        "combined_labels = np.concatenate([y_train, y_val])\n",
        "\n",
        "# Encode the combined labels\n",
        "label_encoder = LabelEncoder()\n",
        "combined_labels_encoded = label_encoder.fit_transform(combined_labels)\n",
        "\n",
        "# Use the label encoder to transform both training and validation labels\n",
        "y_train_encoded = combined_labels_encoded[:len(y_train)]\n",
        "y_val_encoded = combined_labels_encoded[len(y_train):]\n",
        "\n",
        "# Determine the input shape based on the length of flattened fingerprint vectors\n",
        "input_shape = len(flattened_smiles_list[0])\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation='relu', input_shape=(input_shape,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_numerical, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_val_numerical, y_val_encoded))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKZ4ANKx8QYN",
        "outputId": "afcfcbc9-3d07-4b54-c0d0-3f7dcb24c01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "3/3 [==============================] - 1s 125ms/step - loss: 1349.2025 - mae: 28.9062 - val_loss: 1393.4646 - val_mae: 30.4102\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1172.9910 - mae: 26.5454 - val_loss: 1308.0671 - val_mae: 29.3011\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1033.8851 - mae: 24.6075 - val_loss: 1212.0670 - val_mae: 28.0593\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 877.9229 - mae: 22.3563 - val_loss: 1103.5017 - val_mae: 26.8137\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 719.6597 - mae: 19.8100 - val_loss: 981.8629 - val_mae: 25.4241\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 541.2590 - mae: 16.7363 - val_loss: 854.6725 - val_mae: 23.8218\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 383.4366 - mae: 13.4429 - val_loss: 722.4869 - val_mae: 22.2229\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 245.0895 - mae: 10.3037 - val_loss: 596.3438 - val_mae: 20.4183\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 160.4022 - mae: 8.3030 - val_loss: 489.2313 - val_mae: 18.9555\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 110.1421 - mae: 7.4057 - val_loss: 421.0572 - val_mae: 17.9803\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7aa558280790>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tsmiles_list = []\n",
        "for i, j in zip(tsmiles_a, tsmiles_b):\n",
        "    fingerprint_i = convert_smiles_to_fingerprints(i)\n",
        "    fingerprint_j = convert_smiles_to_fingerprints(j)\n",
        "    tsmiles_list.append([fingerprint_i, fingerprint_j])"
      ],
      "metadata": {
        "id": "F7fkrLoV-z3Y"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9WW9FNKClxBp"
      },
      "outputs": [],
      "source": [
        "# Flatten the list of fingerprints for test data\n",
        "tflattened_smiles_list = np.array(tsmiles_list).reshape(len(tsmiles_list), -1)\n",
        "\n",
        "# Preprocess numerical features\n",
        "X_test_numerical = numerical_scaler.transform(tflattened_smiles_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test_numerical)"
      ],
      "metadata": {
        "id": "cETyyRLGE5Vs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76d362cb-8582-4ee6-9b1e-37576e5856d0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 4ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl4baghra1va"
      },
      "outputs": [],
      "source": [
        "import cairosvg\n",
        "from PIL import Image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv8fus9iirWC",
        "outputId": "f76518e6-9ca8-40e8-e57e-ab268c6d6876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cairosvg\n",
            "  Downloading CairoSVG-2.7.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m886.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cairocffi (from cairosvg)\n",
            "  Downloading cairocffi-1.6.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.1/75.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cssselect2 (from cairosvg)\n",
            "  Downloading cssselect2-0.7.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from cairosvg) (0.7.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from cairosvg) (9.4.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from cairosvg) (1.2.1)\n",
            "Requirement already satisfied: cffi>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from cairocffi->cairosvg) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from cssselect2->cairosvg) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.21)\n",
            "Installing collected packages: cssselect2, cairocffi, cairosvg\n",
            "Successfully installed cairocffi-1.6.1 cairosvg-2.7.1 cssselect2-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install cairosvg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jw-GLOAfRzZX"
      },
      "outputs": [],
      "source": [
        "def extract_images_from_svg(svg_file):\n",
        "    png_file = svg_file.replace('.svg', '.png')\n",
        "\n",
        "    # Convert SVG to PNG using CairoSVG\n",
        "    cairosvg.svg2png(url=svg_file, write_to=png_file)\n",
        "    return png_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIlU7ma6ULn0"
      },
      "outputs": [],
      "source": [
        "svg_files = [os.path.join(train_data_images_path, file) for file in train_data_images if file.endswith('.svg')]\n",
        "a_images=[]\n",
        "b_images=[]\n",
        "for svg_file in svg_files:\n",
        "    png_img_path = extract_images_from_svg(svg_file)\n",
        "    #png_img_path=preprocess_image(png_img_p)\n",
        "    if png_img_path[104:105]=='a':\n",
        "      a_images.append(png_img_path)\n",
        "    elif png_img_path[104:105]=='b':\n",
        "      b_images.append(png_img_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBghB6Ra8GCt"
      },
      "outputs": [],
      "source": [
        "images_data = [[] for _ in range(101)]  # Initialize a list of lists for each number (0-100)\n",
        "for img_path in a_images + b_images:\n",
        "    molecule_num = int(img_path.split('_')[-1][:3])  # Extract the molecule number\n",
        "    images_data[molecule_num].append(img_path)\n",
        "images_data.pop(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sqdxt2XN3w4"
      },
      "outputs": [],
      "source": [
        "# Convert images_data to numpy arrays for input to the model\n",
        "image_pairs = np.array(images_data)  # Assuming images_data contains pairs of preprocessed images\n",
        "frac_similar_values = np.array(train_data['frac_similar'])  # Assuming frac_similar is a column from train_data\n",
        "print(image_pairs)\n",
        "# Assuming your image_pairs are of shape (num_samples, 2, img_width, img_height, img_channels)\n",
        "# Reshape to (num_samples, img_width, img_height, img_channels) for each image in the pair\n",
        "#image_pairs = image_pairs.reshape(-1, 2, img_width, img_height, img_channels)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQfJ+dp5biEcxL72WnlLh9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}